{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50aec6ce-4eb4-4bc8-a205-3bfb14130b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ninja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ninja\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import clip\n",
    "import torch\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da6f698-7faa-4f0a-a2ea-614a713e3013",
   "metadata": {},
   "source": [
    "Loading Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3631ee42-c52c-4464-9d03-a74e42d9c2e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caption</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Head CT demonstrating left parotiditis.</td>\n",
       "      <td>ROCOv2_2023_train_000001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acquired renal cysts in end-stage renal failur...</td>\n",
       "      <td>ROCOv2_2023_train_000002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Computed tomography of the chest showing the r...</td>\n",
       "      <td>ROCOv2_2023_train_000003.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lateral view of the sacrum showing the low con...</td>\n",
       "      <td>ROCOv2_2023_train_000004.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thoracic CT scan showing perihilar pulmonary l...</td>\n",
       "      <td>ROCOv2_2023_train_000005.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Caption  \\\n",
       "0            Head CT demonstrating left parotiditis.   \n",
       "1  Acquired renal cysts in end-stage renal failur...   \n",
       "2  Computed tomography of the chest showing the r...   \n",
       "3  Lateral view of the sacrum showing the low con...   \n",
       "4  Thoracic CT scan showing perihilar pulmonary l...   \n",
       "\n",
       "                          Image  \n",
       "0  ROCOv2_2023_train_000001.jpg  \n",
       "1  ROCOv2_2023_train_000002.jpg  \n",
       "2  ROCOv2_2023_train_000003.jpg  \n",
       "3  ROCOv2_2023_train_000004.jpg  \n",
       "4  ROCOv2_2023_train_000005.jpg  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_directory = \"../QL4POMR/Datasets/ROCO2/\"\n",
    "df_train = pd.read_csv(data_directory+\"train_captions.csv\")\n",
    "df_train['Image'] = df_train['ID'] + '.jpg'\n",
    "df_train = df_train.drop(columns=['ID'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38b47f2-3481-4430-a1a0-0f88408cc921",
   "metadata": {},
   "source": [
    "Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af39464f-115f-45dd-b4c5-070a250e6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing function\n",
    "def preprocess_caption(caption):\n",
    "    caption = caption.lower()\n",
    "    caption = re.sub(r'[^\\w\\s]', '', caption)\n",
    "    tokens = word_tokenize(caption)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    preprocessed_caption = ' '.join(tokens)\n",
    "    return preprocessed_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0367ca74-058b-4eaa-a530-f7fdaa187c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length of the string column is: 2278\n",
      "The average length of the string column is: 115.84043348902149\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to the captions\n",
    "df_train['Caption'] = df_train['Caption'].apply(preprocess_caption)\n",
    "df_train.head()\n",
    "max_length = df_train['Caption'].str.len().max()\n",
    "print(\"The maximum length of the string column is:\", max_length)\n",
    "avg_length = df_train['Caption'].str.len().mean()\n",
    "print(\"The average length of the string column is:\", avg_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cc0fd86-5ffe-4748-b95a-0596cb2b233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROCO2Dataset(Dataset):\n",
    "    def __init__(self, dataframe, image_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.image_dir, self.dataframe.iloc[idx, 1])\n",
    "        image = Image.open(img_name).convert(\"RGB\")\n",
    "        caption = self.dataframe.iloc[idx, 0]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Truncate the caption if it is too long for CLIP(Context length max 77)\n",
    "        if len(caption) > 77:\n",
    "            caption = caption[:77]\n",
    "        \n",
    "        return image, caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4ef6885-e83d-4c4c-86ac-7a04948b80e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset and dataloader\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# Modify dataset to use CLIP's preprocessing\n",
    "dataset = ROCO2Dataset(df_train, data_directory+\"train_images/train/\", transform=preprocess)\n",
    "#Batch size was originally 32\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ee971b2-faa4-4da0-aad0-2bae00f315cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: nan\n",
      "Epoch 2/10, Loss: nan\n",
      "Epoch 3/10, Loss: nan\n",
      "Epoch 4/10, Loss: nan\n",
      "Epoch 5/10, Loss: nan\n",
      "Epoch 6/10, Loss: nan\n",
      "Epoch 7/10, Loss: nan\n",
      "Epoch 8/10, Loss: nan\n",
      "Epoch 9/10, Loss: nan\n",
      "Epoch 10/10, Loss: nan\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "# Originally 10 epochs\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for images, texts in dataloader:\n",
    "        images = images.to(device)\n",
    "        texts = clip.tokenize(texts).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits_per_image, logits_per_text = model(images, texts)\n",
    "        ground_truth = torch.arange(len(images), device=device)\n",
    "        loss = (torch.nn.CrossEntropyLoss()(logits_per_image, ground_truth) +\n",
    "                torch.nn.CrossEntropyLoss()(logits_per_text, ground_truth)) / 2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(dataloader)}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'clip_roco2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7c1b75-0f5f-4bc8-b2f5-adbea1a4463b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
